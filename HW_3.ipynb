{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ece8636",
   "metadata": {},
   "source": [
    "### 3. Embedding word2vec fasttext\n",
    "Задача: поиск похожих по эмбеддингам\n",
    "\n",
    "Скачиваем датасет (источник): положительные, отрицательные.\n",
    "\n",
    "или можно через ноутбук\n",
    "\n",
    "!wget https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv?dl=0\n",
    "!wget https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv?dl=0\n",
    "\n",
    "рабочие ссылки с твитами\n",
    "https://disk.yandex.ru/i/v5HM-ENiGXZVpQ\n",
    "https://disk.yandex.ru/i/koR5eMCToCZS2Q\n",
    "\n",
    "В связи с удалением даных можно взять другой датасет, к примеру\n",
    "\n",
    "!wget https://github.com/ods-ai-ml4sg/proj_news_viz/releases/download/data/gazeta.csv.gz\n",
    "\n",
    "#### пример работы с ним \n",
    "from corus import load_ods_gazeta\n",
    "path = 'gazeta.csv.gz'\n",
    "records = load_ods_gazeta(path)\n",
    "next(records)\n",
    "что надо сделать\n",
    "1. объединить в одну выборку\n",
    "2. на основе word2vec/fasttext слоя Embedding реализовать метод поиска ближайших твитов\n",
    "(на вход метода должен приходить запрос (какой-то твит, вопрос) и количество вариантов вывода к примеру 5-ть, ваш метод должен возвращать 5-ть ближайших твитов к этому запросу)\n",
    "3. Проверить насколько хорошо работают подходы\n",
    "\n",
    "для новостных статей задание такое же\n",
    "1. на основе word2vec/fasttext слоя Embedding реализовать метод поиска ближайших статей\n",
    "(на вход метода должен приходить запрос (какой-то вопрос) и количество вариантов вывода к примеру 5-ть, ваш метод должен возвращать 5-ть ближайших статей к этому запросу)\n",
    "2. Проверить насколько хорошо работают подходы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4158a1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import word_tokenize\n",
    "from string import punctuation\n",
    "import nltk\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "# Отключить вывод ошибок\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a9fd59",
   "metadata": {},
   "source": [
    "Посмотрим на данные и объединим в одну выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2a5116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = pd.read_csv('positive.csv', sep=';', usecols=[3], names=['text'])\n",
    "positive['label'] = ['positive'] * len(positive)\n",
    "negative = pd.read_csv('negative.csv', sep=';', usecols=[3], names=['text'])\n",
    "negative['label'] = ['negative'] * len(negative)\n",
    "df = positive.append(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "389edf82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@first_timee хоть я и школота, но поверь, у на...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Да, все-таки он немного похож на него. Но мой ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @KatiaCheh: Ну ты идиотка) я испугалась за ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @digger2912: \"Кто то в углу сидит и погибае...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@irina_dyshkant Вот что значит страшилка :D\\nН...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label\n",
       "0  @first_timee хоть я и школота, но поверь, у на...  positive\n",
       "1  Да, все-таки он немного похож на него. Но мой ...  positive\n",
       "2  RT @KatiaCheh: Ну ты идиотка) я испугалась за ...  positive\n",
       "3  RT @digger2912: \"Кто то в углу сидит и погибае...  positive\n",
       "4  @irina_dyshkant Вот что значит страшилка :D\\nН...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c3c4ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_pattern(text, pattern):\n",
    "    return re.sub(pattern, ' ', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6d353a",
   "metadata": {},
   "source": [
    "на основе word2vec/fasttext слоя Embedding реализовать метод поиска ближайших твитов (на вход метода должен приходить запрос (какой-то твит, вопрос) и количество вариантов вывода к примеру 5-ть, ваш метод должен возвращать 5-ть ближайших твитов к этому запросу)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e2c2dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.info()['models'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd6806c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "woman: 0.7172\n"
     ]
    }
   ],
   "source": [
    "word_vectors = api.load(\"glove-wiki-gigaword-100\")  # загрузим предтренированные вектора слов из gensim-data\n",
    "# выведем слово наиболее близкое к 'man', 'child' и далекое от 'cat'\n",
    "result = word_vectors.most_similar(positive=['man', 'child'], negative=['cat'])\n",
    "print(\"{}: {:.4f}\".format(*result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db547198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cereal\n",
      "summer\n"
     ]
    }
   ],
   "source": [
    "# выведем лишнее слово\n",
    "print(word_vectors.doesnt_match(\"breakfast cereal dinner lunch\".split()))\n",
    "\n",
    "print(word_vectors.doesnt_match(\"black green summer brown\".split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "504ae7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6682648\n",
      "0.8323494\n",
      "0.5261841\n"
     ]
    }
   ],
   "source": [
    "# определим схожесть между словами\n",
    "similarity = word_vectors.similarity('child', 'man')\n",
    "print(similarity)\n",
    "\n",
    "similarity = word_vectors.similarity('woman', 'man')\n",
    "print(similarity)\n",
    "\n",
    "similarity = word_vectors.similarity('cat', 'man')\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97ac5ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('woman', 0.8323495388031006), ('boy', 0.7914870977401733), ('one', 0.7788748145103455), ('person', 0.7526815533638), ('another', 0.7522234916687012)]\n",
      "[('dog', 0.8798074722290039), ('rabbit', 0.7424427270889282), ('cats', 0.732300341129303), ('monkey', 0.7288709878921509), ('pet', 0.719014048576355)]\n",
      "[('children', 0.8553194999694824), ('mother', 0.7771132588386536), ('parents', 0.7735786437988281), ('girl', 0.7634811997413635), ('woman', 0.7601762413978577)]\n"
     ]
    }
   ],
   "source": [
    "# найдем top-5 самых близких слов\n",
    "result = word_vectors.similar_by_word(\"man\", topn=5)\n",
    "print(result)\n",
    "\n",
    "result = word_vectors.similar_by_word(\"cat\", topn=5)\n",
    "print(result)\n",
    "\n",
    "result = word_vectors.similar_by_word(\"child\", topn=5)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd1a491a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting annoy\n",
      "  Downloading annoy-1.17.3.tar.gz (647 kB)\n",
      "     ---------------------------------------- 0.0/647.5 kB ? eta -:--:--\n",
      "     - -------------------------------------- 30.7/647.5 kB ? eta -:--:--\n",
      "     ------- ------------------------------ 122.9/647.5 kB 1.4 MB/s eta 0:00:01\n",
      "     --------------- ---------------------- 256.0/647.5 kB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------- --------------- 389.1/647.5 kB 2.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- 647.5/647.5 kB 3.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: annoy\n",
      "  Building wheel for annoy (setup.py): started\n",
      "  Building wheel for annoy (setup.py): finished with status 'done'\n",
      "  Created wheel for annoy: filename=annoy-1.17.3-cp311-cp311-win_amd64.whl size=52188 sha256=92f1903f11a23aa2a63abe4d587785d1856f9c35168c0bab37cb3433cc9fada4\n",
      "  Stored in directory: c:\\users\\инна\\appdata\\local\\pip\\cache\\wheels\\33\\e5\\58\\0a3e34b92bedf09b4c57e37a63ff395ade6f6c1099ba59877c\n",
      "Successfully built annoy\n",
      "Installing collected packages: annoy\n",
      "Successfully installed annoy-1.17.3\n"
     ]
    }
   ],
   "source": [
    "!pip install annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e65a2761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pymorphy2\n",
    "\n",
    "from stop_words import get_stop_words\n",
    "import annoy\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34cd644b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__label__2 Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^\\t__label__2 The best soundtrack ever to anything.: I'm reading a lot of reviews saying that this is the best 'game soundtrack' and I figured that I'd write a review to disagree a bit. This in my opinino is Yasunori Mitsuda's ultimate masterpiece. The music is timeless and I'm been listening to it for years now and its beauty simply refuses to fade.The price tag on this is pretty staggering I must say, but if you are going to buy any cd for this much money, this is the only one that I feel would be worth every penny.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [__label__2 Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^\t__label__2 The best soundtrack ever to anything.: I'm reading a lot of reviews saying that this is the best 'game soundtrack' and I figured that I'd write a review to disagree a bit. This in my opinino is Yasunori Mitsuda's ultimate masterpiece. The music is timeless and I'm been listening to it for years now and its beauty simply refuses to fade.The price tag on this is pretty staggering I must say, but if you are going to buy any cd for this much money, this is the only one that I feel would be worth every penny.]\n",
       "Index: []"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers=pd.read_csv('prepared_answers.txt', sep=';')\n",
    "answers.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0f9046b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe693a7ddaf4376ab1d270dde6b23c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert True\n",
    "\n",
    "question = None\n",
    "written = False\n",
    "\n",
    "with open(\"prepared_answers.txt\", \"w\") as fout:\n",
    "    with open(\"corpus\", \"r\") as fin:\n",
    "        for line in tqdm_notebook(fin):\n",
    "            if line.startswith(\"---\"):\n",
    "                written = False\n",
    "                continue\n",
    "            if not written and question is not None:\n",
    "                fout.write(question.replace(\"\\t\", \" \").strip() + \"\\t\" + line.replace(\"\\t\", \" \"))\n",
    "                written = True\n",
    "                question = None\n",
    "                continue\n",
    "            if not written:\n",
    "                question = line.strip()\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0763aa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_txt(line):\n",
    "    spls = \"\".join(i for i in line.strip() if i not in exclude).split()\n",
    "    spls = [morph.parse(i.lower())[0].normal_form for i in spls]\n",
    "    #spls = [i for i in spls if i not in sw and i != \"\"]\n",
    "    return spls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "42741531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymorphy3\n",
      "  Obtaining dependency information for pymorphy3 from https://files.pythonhosted.org/packages/d7/f9/ffb9afde503dc6bb2361ea79ceaea18138fbcee32aec4c5d8efa49180753/pymorphy3-1.2.1-py3-none-any.whl.metadata\n",
      "  Downloading pymorphy3-1.2.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\anaconda\\lib\\site-packages (from pymorphy3) (0.7.2)\n",
      "Collecting docopt-ng>=0.6 (from pymorphy3)\n",
      "  Obtaining dependency information for docopt-ng>=0.6 from https://files.pythonhosted.org/packages/6c/4a/c3b77fc1a24510b08918b43a473410c0168f6e657118807015f1f1edceea/docopt_ng-0.9.0-py3-none-any.whl.metadata\n",
      "  Downloading docopt_ng-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pymorphy3-dicts-ru (from pymorphy3)\n",
      "  Downloading pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl (8.4 MB)\n",
      "     ---------------------------------------- 0.0/8.4 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.1/8.4 MB 1.7 MB/s eta 0:00:06\n",
      "     - -------------------------------------- 0.2/8.4 MB 2.8 MB/s eta 0:00:03\n",
      "     -- ------------------------------------- 0.5/8.4 MB 3.8 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 1.0/8.4 MB 5.8 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 2.3/8.4 MB 10.3 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 3.9/8.4 MB 14.6 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 5.6/8.4 MB 17.8 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 7.2/8.4 MB 20.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  8.4/8.4 MB 21.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 8.4/8.4 MB 18.6 MB/s eta 0:00:00\n",
      "Downloading pymorphy3-1.2.1-py3-none-any.whl (55 kB)\n",
      "   ---------------------------------------- 0.0/55.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 55.4/55.4 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading docopt_ng-0.9.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: pymorphy3-dicts-ru, docopt-ng, pymorphy3\n",
      "Successfully installed docopt-ng-0.9.0 pymorphy3-1.2.1 pymorphy3-dicts-ru-2.4.417150.4580142\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "77a7a840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb439443d9f4df3b3bf2340f0694ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import inspect\n",
    "import pymorphy3\n",
    "assert True\n",
    "\n",
    "#подготовка к обучению\n",
    "\n",
    "sentences = []\n",
    "\n",
    "morph = pymorphy3.MorphAnalyzer()\n",
    "exclude = set(string.punctuation)\n",
    "c = 0\n",
    "\n",
    "with open(\"corpus\", \"r\") as fin:\n",
    "\n",
    "    for line in tqdm_notebook(fin):\n",
    "        spls = preprocess_txt(line)\n",
    "        sentences.append(spls)\n",
    "        c += 1\n",
    "        if c > 100000:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0276d7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentences = [token for tweet in df.text for token in word_tokenize(tweet) if token not in punctuation]\n",
    "#print(len(sentences))\n",
    "#sentences[:10]\n",
    "sentences = [i for i in sentences if len(i) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c031b423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['label2',\n",
       "  'stuning',\n",
       "  'even',\n",
       "  'for',\n",
       "  'the',\n",
       "  'nongamer',\n",
       "  'this',\n",
       "  'sound',\n",
       "  'track',\n",
       "  'was',\n",
       "  'beautiful',\n",
       "  'it',\n",
       "  'paints',\n",
       "  'the',\n",
       "  'senery',\n",
       "  'in',\n",
       "  'your',\n",
       "  'mind',\n",
       "  'so',\n",
       "  'well',\n",
       "  'i',\n",
       "  'would',\n",
       "  'recomend',\n",
       "  'it',\n",
       "  'even',\n",
       "  'to',\n",
       "  'people',\n",
       "  'who',\n",
       "  'hate',\n",
       "  'vid',\n",
       "  'game',\n",
       "  'music',\n",
       "  'i',\n",
       "  'have',\n",
       "  'played',\n",
       "  'the',\n",
       "  'game',\n",
       "  'chrono',\n",
       "  'cross',\n",
       "  'but',\n",
       "  'out',\n",
       "  'of',\n",
       "  'all',\n",
       "  'of',\n",
       "  'the',\n",
       "  'games',\n",
       "  'i',\n",
       "  'have',\n",
       "  'ever',\n",
       "  'played',\n",
       "  'it',\n",
       "  'has',\n",
       "  'the',\n",
       "  'best',\n",
       "  'music',\n",
       "  'it',\n",
       "  'backs',\n",
       "  'away',\n",
       "  'from',\n",
       "  'crude',\n",
       "  'keyboarding',\n",
       "  'and',\n",
       "  'takes',\n",
       "  'a',\n",
       "  'fresher',\n",
       "  'step',\n",
       "  'with',\n",
       "  'grate',\n",
       "  'guitars',\n",
       "  'and',\n",
       "  'soulful',\n",
       "  'orchestras',\n",
       "  'it',\n",
       "  'would',\n",
       "  'impress',\n",
       "  'anyone',\n",
       "  'who',\n",
       "  'cares',\n",
       "  'to',\n",
       "  'listen'],\n",
       " ['label2',\n",
       "  'the',\n",
       "  'best',\n",
       "  'soundtrack',\n",
       "  'ever',\n",
       "  'to',\n",
       "  'anything',\n",
       "  'im',\n",
       "  'reading',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'reviews',\n",
       "  'saying',\n",
       "  'that',\n",
       "  'this',\n",
       "  'is',\n",
       "  'the',\n",
       "  'best',\n",
       "  'game',\n",
       "  'soundtrack',\n",
       "  'and',\n",
       "  'i',\n",
       "  'figured',\n",
       "  'that',\n",
       "  'id',\n",
       "  'write',\n",
       "  'a',\n",
       "  'review',\n",
       "  'to',\n",
       "  'disagree',\n",
       "  'a',\n",
       "  'bit',\n",
       "  'this',\n",
       "  'in',\n",
       "  'my',\n",
       "  'opinino',\n",
       "  'is',\n",
       "  'yasunori',\n",
       "  'mitsudas',\n",
       "  'ultimate',\n",
       "  'masterpiece',\n",
       "  'the',\n",
       "  'music',\n",
       "  'is',\n",
       "  'timeless',\n",
       "  'and',\n",
       "  'im',\n",
       "  'been',\n",
       "  'listening',\n",
       "  'to',\n",
       "  'it',\n",
       "  'for',\n",
       "  'years',\n",
       "  'now',\n",
       "  'and',\n",
       "  'its',\n",
       "  'beauty',\n",
       "  'simply',\n",
       "  'refuses',\n",
       "  'to',\n",
       "  'fadethe',\n",
       "  'price',\n",
       "  'tag',\n",
       "  'on',\n",
       "  'this',\n",
       "  'is',\n",
       "  'pretty',\n",
       "  'staggering',\n",
       "  'i',\n",
       "  'must',\n",
       "  'say',\n",
       "  'but',\n",
       "  'if',\n",
       "  'you',\n",
       "  'are',\n",
       "  'going',\n",
       "  'to',\n",
       "  'buy',\n",
       "  'any',\n",
       "  'cd',\n",
       "  'for',\n",
       "  'this',\n",
       "  'much',\n",
       "  'money',\n",
       "  'this',\n",
       "  'is',\n",
       "  'the',\n",
       "  'only',\n",
       "  'one',\n",
       "  'that',\n",
       "  'i',\n",
       "  'feel',\n",
       "  'would',\n",
       "  'be',\n",
       "  'worth',\n",
       "  'every',\n",
       "  'penny'],\n",
       " ['label2',\n",
       "  'amazing',\n",
       "  'this',\n",
       "  'soundtrack',\n",
       "  'is',\n",
       "  'my',\n",
       "  'favorite',\n",
       "  'music',\n",
       "  'of',\n",
       "  'all',\n",
       "  'time',\n",
       "  'hands',\n",
       "  'down',\n",
       "  'the',\n",
       "  'intense',\n",
       "  'sadness',\n",
       "  'of',\n",
       "  'prisoners',\n",
       "  'of',\n",
       "  'fate',\n",
       "  'which',\n",
       "  'means',\n",
       "  'all',\n",
       "  'the',\n",
       "  'more',\n",
       "  'if',\n",
       "  'youve',\n",
       "  'played',\n",
       "  'the',\n",
       "  'game',\n",
       "  'and',\n",
       "  'the',\n",
       "  'hope',\n",
       "  'in',\n",
       "  'a',\n",
       "  'distant',\n",
       "  'promise',\n",
       "  'and',\n",
       "  'girl',\n",
       "  'who',\n",
       "  'stole',\n",
       "  'the',\n",
       "  'star',\n",
       "  'have',\n",
       "  'been',\n",
       "  'an',\n",
       "  'important',\n",
       "  'inspiration',\n",
       "  'to',\n",
       "  'me',\n",
       "  'personally',\n",
       "  'throughout',\n",
       "  'my',\n",
       "  'teen',\n",
       "  'years',\n",
       "  'the',\n",
       "  'higher',\n",
       "  'energy',\n",
       "  'tracks',\n",
       "  'like',\n",
       "  'chrono',\n",
       "  'cross',\n",
       "  'times',\n",
       "  'scar',\n",
       "  'time',\n",
       "  'of',\n",
       "  'the',\n",
       "  'dreamwatch',\n",
       "  'and',\n",
       "  'chronomantique',\n",
       "  'indefinably',\n",
       "  'remeniscent',\n",
       "  'of',\n",
       "  'chrono',\n",
       "  'trigger',\n",
       "  'are',\n",
       "  'all',\n",
       "  'absolutely',\n",
       "  'superb',\n",
       "  'as',\n",
       "  'wellthis',\n",
       "  'soundtrack',\n",
       "  'is',\n",
       "  'amazing',\n",
       "  'music',\n",
       "  'probably',\n",
       "  'the',\n",
       "  'best',\n",
       "  'of',\n",
       "  'this',\n",
       "  'composers',\n",
       "  'work',\n",
       "  'i',\n",
       "  'havent',\n",
       "  'heard',\n",
       "  'the',\n",
       "  'xenogears',\n",
       "  'soundtrack',\n",
       "  'so',\n",
       "  'i',\n",
       "  'cant',\n",
       "  'say',\n",
       "  'for',\n",
       "  'sure',\n",
       "  'and',\n",
       "  'even',\n",
       "  'if',\n",
       "  'youve',\n",
       "  'never',\n",
       "  'played',\n",
       "  'the',\n",
       "  'game',\n",
       "  'it',\n",
       "  'would',\n",
       "  'be',\n",
       "  'worth',\n",
       "  'twice',\n",
       "  'the',\n",
       "  'price',\n",
       "  'to',\n",
       "  'buy',\n",
       "  'iti',\n",
       "  'wish',\n",
       "  'i',\n",
       "  'could',\n",
       "  'give',\n",
       "  'it',\n",
       "  '6',\n",
       "  'stars'],\n",
       " ['label2',\n",
       "  'excellent',\n",
       "  'soundtrack',\n",
       "  'i',\n",
       "  'truly',\n",
       "  'like',\n",
       "  'this',\n",
       "  'soundtrack',\n",
       "  'and',\n",
       "  'i',\n",
       "  'enjoy',\n",
       "  'video',\n",
       "  'game',\n",
       "  'music',\n",
       "  'i',\n",
       "  'have',\n",
       "  'played',\n",
       "  'this',\n",
       "  'game',\n",
       "  'and',\n",
       "  'most',\n",
       "  'of',\n",
       "  'the',\n",
       "  'music',\n",
       "  'on',\n",
       "  'here',\n",
       "  'i',\n",
       "  'enjoy',\n",
       "  'and',\n",
       "  'its',\n",
       "  'truly',\n",
       "  'relaxing',\n",
       "  'and',\n",
       "  'peacefulon',\n",
       "  'disk',\n",
       "  'one',\n",
       "  'my',\n",
       "  'favorites',\n",
       "  'are',\n",
       "  'scars',\n",
       "  'of',\n",
       "  'time',\n",
       "  'between',\n",
       "  'life',\n",
       "  'and',\n",
       "  'death',\n",
       "  'forest',\n",
       "  'of',\n",
       "  'illusion',\n",
       "  'fortress',\n",
       "  'of',\n",
       "  'ancient',\n",
       "  'dragons',\n",
       "  'lost',\n",
       "  'fragment',\n",
       "  'and',\n",
       "  'drowned',\n",
       "  'valleydisk',\n",
       "  'two',\n",
       "  'the',\n",
       "  'draggons',\n",
       "  'galdorb',\n",
       "  'home',\n",
       "  'chronomantique',\n",
       "  'prisoners',\n",
       "  'of',\n",
       "  'fate',\n",
       "  'gale',\n",
       "  'and',\n",
       "  'my',\n",
       "  'girlfriend',\n",
       "  'likes',\n",
       "  'zelbessdisk',\n",
       "  'three',\n",
       "  'the',\n",
       "  'best',\n",
       "  'of',\n",
       "  'the',\n",
       "  'three',\n",
       "  'garden',\n",
       "  'of',\n",
       "  'god',\n",
       "  'chronopolis',\n",
       "  'fates',\n",
       "  'jellyfish',\n",
       "  'sea',\n",
       "  'burning',\n",
       "  'orphange',\n",
       "  'dragons',\n",
       "  'prayer',\n",
       "  'tower',\n",
       "  'of',\n",
       "  'stars',\n",
       "  'dragon',\n",
       "  'god',\n",
       "  'and',\n",
       "  'radical',\n",
       "  'dreamers',\n",
       "  'unstealable',\n",
       "  'jeweloverall',\n",
       "  'this',\n",
       "  'is',\n",
       "  'a',\n",
       "  'excellent',\n",
       "  'soundtrack',\n",
       "  'and',\n",
       "  'should',\n",
       "  'be',\n",
       "  'brought',\n",
       "  'by',\n",
       "  'those',\n",
       "  'that',\n",
       "  'like',\n",
       "  'video',\n",
       "  'game',\n",
       "  'musicxander',\n",
       "  'cross']]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5a4acc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelW2V = Word2Vec(sentences=sentences, vector_size=300, window=5, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "617f78f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFT = FastText(sentences=sentences, vector_size=300, min_count=1, window=5, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "36cb366c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f005f841a5943bb95f5268156131011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_index = annoy.AnnoyIndex(300 ,'angular')\n",
    "ft_index = annoy.AnnoyIndex(300 ,'angular')\n",
    "\n",
    "index_map = {}\n",
    "counter = 0\n",
    "\n",
    "with open(\"corpus\", \"r\") as f:\n",
    "    for line in tqdm_notebook(f):\n",
    "        n_w2v = 0\n",
    "        n_ft = 0\n",
    "        spls = line.split(\"\\t\")\n",
    "        index_map[counter] = spls[0]\n",
    "        question = preprocess_txt(spls[0])\n",
    "        \n",
    "        vector_w2v = np.zeros(300)\n",
    "        vector_ft = np.zeros(300)\n",
    "        for word in question:\n",
    "            if word in modelW2V.wv:\n",
    "                vector_w2v += modelW2V.wv[word]\n",
    "                n_w2v += 1\n",
    "            if word in modelFT.wv:\n",
    "                vector_ft += modelFT.wv[word]\n",
    "                n_ft += 1\n",
    "        if n_w2v > 0:\n",
    "            vector_w2v = vector_w2v / n_w2v\n",
    "        if n_ft > 0:\n",
    "            vector_ft = vector_ft / n_ft\n",
    "        w2v_index.add_item(counter, vector_w2v)\n",
    "        ft_index.add_item(counter, vector_ft)\n",
    "            \n",
    "        counter += 1\n",
    "        \n",
    "        if counter > 100000:\n",
    "            break\n",
    "\n",
    "w2v_index.build(10)\n",
    "ft_index.build(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ead04d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(question, index, model, index_map):\n",
    "    question = preprocess_txt(question)\n",
    "    vector = np.zeros(300)\n",
    "    norm = 0\n",
    "    for word in question:\n",
    "        if word in model.wv:\n",
    "            vector += model.wv[word]\n",
    "            norm += 1\n",
    "    if norm > 0:\n",
    "        vector = vector / norm\n",
    "    answers = index.get_nns_by_vector(vector, 5, )\n",
    "    return [index_map[i] for i in answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7f7de95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"the best track\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3538c825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__label__2 One of the very best.....: This is one of the very best \"rockumentaries\" ever! I loved the whole thing, especially the interviews....especially the ones with the ultra-talented producer/singer/song writer/pianist John Simon-my friend. You might consider checking out John\\'s own recordings.\\n',\n",
       " \"__label__2 One of 20th Century's Greatest: This book contains supreme beauty and the worst ugliness. One of the greatest works of the 20th century, one all should have a go at.\\n\",\n",
       " '__label__2 The Sky is the Limit: The true story of the Lafayette Escadrille comes to life in MGM\\'s action packed war movie \"Flyboys\" The young american men who fought for the French and became the first fighter pilots during the Great War. It\\'s one of the best war movies ever made, a thrill ride into history, the best WWI movie since \"All Quiet on the Western Front\" It\\'s spectacular, a great war film. See \"Flyboys\"\\n',\n",
       " '__label__2 True Prediction: On of the best and prophetic novels ever written about the descent into dehumanizing socialism.\\n',\n",
       " '__label__2 good: The concert was her best. Great twists and turns on the concert, kept my attention most of the time.\\n']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response(TEXT, w2v_index, modelW2V, index_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "64fe3f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__label__2 One of the very best.....: This is one of the very best \"rockumentaries\" ever! I loved the whole thing, especially the interviews....especially the ones with the ultra-talented producer/singer/song writer/pianist John Simon-my friend. You might consider checking out John\\'s own recordings.\\n',\n",
       " \"__label__2 One of 20th Century's Greatest: This book contains supreme beauty and the worst ugliness. One of the greatest works of the 20th century, one all should have a go at.\\n\",\n",
       " '__label__2 The Sky is the Limit: The true story of the Lafayette Escadrille comes to life in MGM\\'s action packed war movie \"Flyboys\" The young american men who fought for the French and became the first fighter pilots during the Great War. It\\'s one of the best war movies ever made, a thrill ride into history, the best WWI movie since \"All Quiet on the Western Front\" It\\'s spectacular, a great war film. See \"Flyboys\"\\n',\n",
       " '__label__2 good: The concert was her best. Great twists and turns on the concert, kept my attention most of the time.\\n',\n",
       " '__label__2 The Best Live Harmony You can Get!: Absolutely the best in Harmony from a great group. The Live performance is one of the best and really brings out their strength as performers and entertainers.\\n']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response(TEXT, ft_index, modelFT, index_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccddaa4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5795fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
