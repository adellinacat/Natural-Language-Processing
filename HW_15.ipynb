{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be8787c8",
   "metadata": {
    "id": "be8787c8"
   },
   "source": [
    "### 15. Консультация по курсовому проекту. Создание чат-бота в Telegram\n",
    "**Задание**\n",
    "Реализовать сценарии поведения для диалоговой системы<br>\n",
    "1. сценарий болталка\n",
    "2. погода в городе\n",
    "3. праздники\n",
    "4. фильмы\n",
    "5. покупка товара\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8123879",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a8123879",
    "outputId": "a9bd82bc-1b2d-4ab9-b646-0ef2a4d1722f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==1.4.0\n",
      "aiohttp==3.9.1\n",
      "aiosignal==1.3.1\n",
      "alabaster==0.7.13\n",
      "albumentations==1.3.1\n",
      "altair==4.2.2\n",
      "anyio==3.7.1\n",
      "appdirs==1.4.4\n",
      "argon2-cffi==23.1.0\n",
      "argon2-cffi-bindings==21.2.0\n",
      "array-record==0.5.0\n",
      "arviz==0.15.1\n",
      "astropy==5.3.4\n",
      "astunparse==1.6.3\n",
      "async-timeout==4.0.3\n",
      "atpublic==4.0\n",
      "attrs==23.1.0\n",
      "audioread==3.0.1\n",
      "autograd==1.6.2\n",
      "Babel==2.13.1\n",
      "backcall==0.2.0\n",
      "beautifulsoup4==4.11.2\n",
      "bidict==0.22.1\n",
      "bigframes==0.15.0\n",
      "bleach==6.1.0\n",
      "blinker==1.4\n",
      "blis==0.7.11\n",
      "blosc2==2.0.0\n",
      "bokeh==3.3.1\n",
      "bqplot==0.12.42\n",
      "branca==0.7.0\n",
      "build==1.0.3\n",
      "CacheControl==0.13.1\n",
      "cachetools==5.3.2\n",
      "catalogue==2.0.10\n",
      "certifi==2023.11.17\n",
      "cffi==1.16.0\n",
      "chardet==5.2.0\n",
      "charset-normalizer==3.3.2\n",
      "chex==0.1.7\n",
      "click==8.1.7\n",
      "click-plugins==1.1.1\n",
      "cligj==0.7.2\n",
      "cloudpickle==2.2.1\n",
      "cmake==3.27.7\n",
      "cmdstanpy==1.2.0\n",
      "colorcet==3.0.1\n",
      "colorlover==0.3.0\n",
      "colour==0.1.5\n",
      "community==1.0.0b1\n",
      "confection==0.1.4\n",
      "cons==0.4.6\n",
      "contextlib2==21.6.0\n",
      "contourpy==1.2.0\n",
      "cryptography==41.0.7\n",
      "cufflinks==0.17.3\n",
      "cupy-cuda11x==11.0.0\n",
      "cvxopt==1.3.2\n",
      "cvxpy==1.3.2\n",
      "cycler==0.12.1\n",
      "cymem==2.0.8\n",
      "Cython==3.0.6\n",
      "dask==2023.8.1\n",
      "datascience==0.17.6\n",
      "db-dtypes==1.1.1\n",
      "dbus-python==1.2.18\n",
      "debugpy==1.6.6\n",
      "decorator==4.4.2\n",
      "defusedxml==0.7.1\n",
      "diskcache==5.6.3\n",
      "distributed==2023.8.1\n",
      "distro==1.7.0\n",
      "dlib==19.24.2\n",
      "dm-tree==0.1.8\n",
      "docutils==0.18.1\n",
      "dopamine-rl==4.0.6\n",
      "duckdb==0.9.2\n",
      "earthengine-api==0.1.381\n",
      "easydict==1.11\n",
      "ecos==2.0.12\n",
      "editdistance==0.6.2\n",
      "eerepr==0.0.4\n",
      "en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl#sha256=83276fc78a70045627144786b52e1f2728ad5e29e5e43916ec37ea9c26a11212\n",
      "entrypoints==0.4\n",
      "et-xmlfile==1.1.0\n",
      "etils==1.5.2\n",
      "etuples==0.3.9\n",
      "exceptiongroup==1.2.0\n",
      "fastai==2.7.13\n",
      "fastcore==1.5.29\n",
      "fastdownload==0.0.7\n",
      "fastjsonschema==2.19.0\n",
      "fastprogress==1.0.3\n",
      "fastrlock==0.8.2\n",
      "filelock==3.13.1\n",
      "fiona==1.9.5\n",
      "firebase-admin==5.3.0\n",
      "Flask==2.2.5\n",
      "flatbuffers==23.5.26\n",
      "flax==0.7.5\n",
      "folium==0.14.0\n",
      "fonttools==4.45.1\n",
      "frozendict==2.3.10\n",
      "frozenlist==1.4.0\n",
      "fsspec==2023.6.0\n",
      "future==0.18.3\n",
      "gast==0.5.4\n",
      "gcsfs==2023.6.0\n",
      "GDAL==3.4.3\n",
      "gdown==4.6.6\n",
      "geemap==0.28.2\n",
      "gensim==4.3.2\n",
      "geocoder==1.38.1\n",
      "geographiclib==2.0\n",
      "geopandas==0.13.2\n",
      "geopy==2.3.0\n",
      "gin-config==0.5.0\n",
      "glob2==0.7\n",
      "google==2.0.3\n",
      "google-ai-generativelanguage==0.3.3\n",
      "google-api-core==2.11.1\n",
      "google-api-python-client==2.84.0\n",
      "google-auth==2.17.3\n",
      "google-auth-httplib2==0.1.1\n",
      "google-auth-oauthlib==1.0.0\n",
      "google-cloud-aiplatform==1.36.4\n",
      "google-cloud-bigquery==3.12.0\n",
      "google-cloud-bigquery-connection==1.12.1\n",
      "google-cloud-bigquery-storage==2.23.0\n",
      "google-cloud-core==2.3.3\n",
      "google-cloud-datastore==2.15.2\n",
      "google-cloud-firestore==2.11.1\n",
      "google-cloud-functions==1.13.3\n",
      "google-cloud-iam==2.12.2\n",
      "google-cloud-language==2.9.1\n",
      "google-cloud-resource-manager==1.10.4\n",
      "google-cloud-storage==2.8.0\n",
      "google-cloud-translate==3.11.3\n",
      "google-colab @ file:///colabtools/dist/google-colab-1.0.0.tar.gz#sha256=96e8c242fb55a2c189a2cf1f0c80424a8ee10e7e331ce75172c3806ac57ba026\n",
      "google-crc32c==1.5.0\n",
      "google-generativeai==0.2.2\n",
      "google-pasta==0.2.0\n",
      "google-resumable-media==2.6.0\n",
      "googleapis-common-protos==1.61.0\n",
      "googledrivedownloader==0.4\n",
      "graphviz==0.20.1\n",
      "greenlet==3.0.1\n",
      "grpc-google-iam-v1==0.12.7\n",
      "grpcio==1.59.3\n",
      "grpcio-status==1.48.2\n",
      "gspread==3.4.2\n",
      "gspread-dataframe==3.3.1\n",
      "gym==0.25.2\n",
      "gym-notices==0.0.8\n",
      "h5netcdf==1.3.0\n",
      "h5py==3.9.0\n",
      "holidays==0.37\n",
      "holoviews==1.17.1\n",
      "html5lib==1.1\n",
      "httpimport==1.3.1\n",
      "httplib2==0.22.0\n",
      "huggingface-hub==0.19.4\n",
      "humanize==4.7.0\n",
      "hyperopt==0.2.7\n",
      "ibis-framework==6.2.0\n",
      "idna==3.6\n",
      "imageio==2.31.6\n",
      "imageio-ffmpeg==0.4.9\n",
      "imagesize==1.4.1\n",
      "imbalanced-learn==0.10.1\n",
      "imgaug==0.4.0\n",
      "importlib-metadata==6.8.0\n",
      "importlib-resources==6.1.1\n",
      "imutils==0.5.4\n",
      "inflect==7.0.0\n",
      "iniconfig==2.0.0\n",
      "install==1.3.5\n",
      "intel-openmp==2023.2.0\n",
      "ipyevents==2.0.2\n",
      "ipyfilechooser==0.6.0\n",
      "ipykernel==5.5.6\n",
      "ipyleaflet==0.18.0\n",
      "ipython==7.34.0\n",
      "ipython-genutils==0.2.0\n",
      "ipython-sql==0.5.0\n",
      "ipytree==0.2.2\n",
      "ipywidgets==7.7.1\n",
      "itsdangerous==2.1.2\n",
      "jax==0.4.20\n",
      "jaxlib @ https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.4.20+cuda11.cudnn86-cp310-cp310-manylinux2014_x86_64.whl#sha256=01be66238133f884bf5adf15cd7eaaf8445f9d4b056c5c64df28a997a6aff2fe\n",
      "jeepney==0.7.1\n",
      "jieba==0.42.1\n",
      "Jinja2==3.1.2\n",
      "joblib==1.3.2\n",
      "jsonpickle==3.0.2\n",
      "jsonschema==4.19.2\n",
      "jsonschema-specifications==2023.11.2\n",
      "jupyter-client==6.1.12\n",
      "jupyter-console==6.1.0\n",
      "jupyter-server==1.24.0\n",
      "jupyter_core==5.5.0\n",
      "jupyterlab-widgets==3.0.9\n",
      "jupyterlab_pygments==0.3.0\n",
      "kaggle==1.5.16\n",
      "keras==2.14.0\n",
      "keyring==23.5.0\n",
      "kiwisolver==1.4.5\n",
      "langcodes==3.3.0\n",
      "launchpadlib==1.10.16\n",
      "lazr.restfulclient==0.14.4\n",
      "lazr.uri==1.0.6\n",
      "lazy_loader==0.3\n",
      "libclang==16.0.6\n",
      "librosa==0.10.1\n",
      "lida==0.0.10\n",
      "lightgbm==4.1.0\n",
      "linkify-it-py==2.0.2\n",
      "llmx==0.0.15a0\n",
      "llvmlite==0.41.1\n",
      "locket==1.0.0\n",
      "logical-unification==0.4.6\n",
      "lxml==4.9.3\n",
      "malloy==2023.1064\n",
      "Markdown==3.5.1\n",
      "markdown-it-py==3.0.0\n",
      "MarkupSafe==2.1.3\n",
      "matplotlib==3.7.1\n",
      "matplotlib-inline==0.1.6\n",
      "matplotlib-venn==0.11.9\n",
      "mdit-py-plugins==0.4.0\n",
      "mdurl==0.1.2\n",
      "miniKanren==1.0.3\n",
      "missingno==0.5.2\n",
      "mistune==0.8.4\n",
      "mizani==0.9.3\n",
      "mkl==2023.2.0\n",
      "ml-dtypes==0.2.0\n",
      "mlxtend==0.22.0\n",
      "more-itertools==10.1.0\n",
      "moviepy==1.0.3\n",
      "mpmath==1.3.0\n",
      "msgpack==1.0.7\n",
      "multidict==6.0.4\n",
      "multipledispatch==1.0.0\n",
      "multitasking==0.0.11\n",
      "murmurhash==1.0.10\n",
      "music21==9.1.0\n",
      "natsort==8.4.0\n",
      "nbclassic==1.0.0\n",
      "nbclient==0.9.0\n",
      "nbconvert==6.5.4\n",
      "nbformat==5.9.2\n",
      "nest-asyncio==1.5.8\n",
      "networkx==3.2.1\n",
      "nibabel==4.0.2\n",
      "nltk==3.8.1\n",
      "notebook==6.5.5\n",
      "notebook_shim==0.2.3\n",
      "numba==0.58.1\n",
      "numexpr==2.8.7\n",
      "numpy==1.23.5\n",
      "oauth2client==4.1.3\n",
      "oauthlib==3.2.2\n",
      "opencv-contrib-python==4.8.0.76\n",
      "opencv-python==4.8.0.76\n",
      "opencv-python-headless==4.8.1.78\n",
      "openpyxl==3.1.2\n",
      "opt-einsum==3.3.0\n",
      "optax==0.1.7\n",
      "orbax-checkpoint==0.4.3\n",
      "osqp==0.6.2.post8\n",
      "packaging==23.2\n",
      "pandas==1.5.3\n",
      "pandas-datareader==0.10.0\n",
      "pandas-gbq==0.17.9\n",
      "pandas-stubs==1.5.3.230304\n",
      "pandocfilters==1.5.0\n",
      "panel==1.3.4\n",
      "param==2.0.1\n",
      "parso==0.8.3\n",
      "parsy==2.1\n",
      "partd==1.4.1\n",
      "pathlib==1.0.1\n",
      "pathy==0.10.3\n",
      "patsy==0.5.3\n",
      "peewee==3.17.0\n",
      "pexpect==4.9.0\n",
      "pickleshare==0.7.5\n",
      "Pillow==9.4.0\n",
      "pip-tools==6.13.0\n",
      "platformdirs==4.0.0\n",
      "plotly==5.15.0\n",
      "plotnine==0.12.4\n",
      "pluggy==1.3.0\n",
      "polars==0.17.3\n",
      "pooch==1.8.0\n",
      "portpicker==1.5.2\n",
      "prefetch-generator==1.0.3\n",
      "preshed==3.0.9\n",
      "prettytable==3.9.0\n",
      "proglog==0.1.10\n",
      "progressbar2==4.2.0\n",
      "prometheus-client==0.19.0\n",
      "promise==2.3\n",
      "prompt-toolkit==3.0.41\n",
      "prophet==1.1.5\n",
      "proto-plus==1.22.3\n",
      "protobuf==3.20.3\n",
      "psutil==5.9.5\n",
      "psycopg2==2.9.9\n",
      "ptyprocess==0.7.0\n",
      "py-cpuinfo==9.0.0\n",
      "py4j==0.10.9.7\n",
      "pyarrow==9.0.0\n",
      "pyasn1==0.5.1\n",
      "pyasn1-modules==0.3.0\n",
      "pycocotools==2.0.7\n",
      "pycparser==2.21\n",
      "pyct==0.5.0\n",
      "pydantic==1.10.13\n",
      "pydata-google-auth==1.8.2\n",
      "pydot==1.4.2\n",
      "pydot-ng==2.0.0\n",
      "pydotplus==2.0.2\n",
      "PyDrive==1.3.1\n",
      "PyDrive2==1.6.3\n",
      "pyerfa==2.0.1.1\n",
      "pygame==2.5.2\n",
      "Pygments==2.16.1\n",
      "PyGObject==3.42.1\n",
      "PyJWT==2.3.0\n",
      "pymc==5.7.2\n",
      "pymystem3==0.2.0\n",
      "PyOpenGL==3.1.7\n",
      "pyOpenSSL==23.3.0\n",
      "pyparsing==3.1.1\n",
      "pyperclip==1.8.2\n",
      "pyproj==3.6.1\n",
      "pyproject_hooks==1.0.0\n",
      "pyshp==2.3.1\n",
      "PySocks==1.7.1\n",
      "pytensor==2.14.2\n",
      "pytest==7.4.3\n",
      "python-apt==0.0.0\n",
      "python-box==7.1.1\n",
      "python-dateutil==2.8.2\n",
      "python-louvain==0.16\n",
      "python-slugify==8.0.1\n",
      "python-utils==3.8.1\n",
      "pytz==2023.3.post1\n",
      "pyviz_comms==3.0.0\n",
      "PyWavelets==1.5.0\n",
      "PyYAML==6.0.1\n",
      "pyzmq==23.2.1\n",
      "qdldl==0.1.7.post0\n",
      "qudida==0.0.4\n",
      "ratelim==0.1.6\n",
      "referencing==0.31.1\n",
      "regex==2023.6.3\n",
      "requests==2.31.0\n",
      "requests-oauthlib==1.3.1\n",
      "requirements-parser==0.5.0\n",
      "rich==13.7.0\n",
      "rpds-py==0.13.2\n",
      "rpy2==3.4.2\n",
      "rsa==4.9\n",
      "safetensors==0.4.1\n",
      "scikit-image==0.19.3\n",
      "scikit-learn==1.2.2\n",
      "scipy==1.11.4\n",
      "scooby==0.9.2\n",
      "scs==3.2.4.post1\n",
      "seaborn==0.12.2\n",
      "SecretStorage==3.3.1\n",
      "Send2Trash==1.8.2\n",
      "shapely==2.0.2\n",
      "six==1.16.0\n",
      "sklearn-pandas==2.2.0\n",
      "smart-open==6.4.0\n",
      "sniffio==1.3.0\n",
      "snowballstemmer==2.2.0\n",
      "sortedcontainers==2.4.0\n",
      "soundfile==0.12.1\n",
      "soupsieve==2.5\n",
      "soxr==0.3.7\n",
      "spacy==3.6.1\n",
      "spacy-legacy==3.0.12\n",
      "spacy-loggers==1.0.5\n",
      "Sphinx==5.0.2\n",
      "sphinxcontrib-applehelp==1.0.7\n",
      "sphinxcontrib-devhelp==1.0.5\n",
      "sphinxcontrib-htmlhelp==2.0.4\n",
      "sphinxcontrib-jsmath==1.0.1\n",
      "sphinxcontrib-qthelp==1.0.6\n",
      "sphinxcontrib-serializinghtml==1.1.9\n",
      "SQLAlchemy==2.0.23\n",
      "sqlglot==17.16.2\n",
      "sqlparse==0.4.4\n",
      "srsly==2.4.8\n",
      "stanio==0.3.0\n",
      "statsmodels==0.14.0\n",
      "sympy==1.12\n",
      "tables==3.8.0\n",
      "tabulate==0.9.0\n",
      "tbb==2021.11.0\n",
      "tblib==3.0.0\n",
      "tenacity==8.2.3\n",
      "tensorboard==2.14.1\n",
      "tensorboard-data-server==0.7.2\n",
      "tensorflow==2.14.0\n",
      "tensorflow-datasets==4.9.3\n",
      "tensorflow-estimator==2.14.0\n",
      "tensorflow-gcs-config==2.14.0\n",
      "tensorflow-hub==0.15.0\n",
      "tensorflow-io-gcs-filesystem==0.34.0\n",
      "tensorflow-metadata==1.14.0\n",
      "tensorflow-probability==0.22.0\n",
      "tensorstore==0.1.45\n",
      "termcolor==2.3.0\n",
      "terminado==0.18.0\n",
      "text-unidecode==1.3\n",
      "textblob==0.17.1\n",
      "tf-slim==1.1.0\n",
      "thinc==8.1.12\n",
      "threadpoolctl==3.2.0\n",
      "tifffile==2023.9.26\n",
      "tinycss2==1.2.1\n",
      "tokenizers==0.15.0\n",
      "toml==0.10.2\n",
      "tomli==2.0.1\n",
      "toolz==0.12.0\n",
      "torch @ https://download.pytorch.org/whl/cu118/torch-2.1.0%2Bcu118-cp310-cp310-linux_x86_64.whl#sha256=a81b554184492005543ddc32e96469f9369d778dedd195d73bda9bed407d6589\n",
      "torchaudio @ https://download.pytorch.org/whl/cu118/torchaudio-2.1.0%2Bcu118-cp310-cp310-linux_x86_64.whl#sha256=cdfd0a129406155eee595f408cafbb92589652da4090d1d2040f5453d4cae71f\n",
      "torchdata==0.7.0\n",
      "torchsummary==1.5.1\n",
      "torchtext==0.16.0\n",
      "torchvision @ https://download.pytorch.org/whl/cu118/torchvision-0.16.0%2Bcu118-cp310-cp310-linux_x86_64.whl#sha256=033712f65d45afe806676c4129dfe601ad1321d9e092df62b15847c02d4061dc\n",
      "tornado==6.3.2\n",
      "tqdm==4.66.1\n",
      "traitlets==5.7.1\n",
      "traittypes==0.2.1\n",
      "transformers==4.35.2\n",
      "triton==2.1.0\n",
      "tweepy==4.14.0\n",
      "typer==0.9.0\n",
      "types-pytz==2023.3.1.1\n",
      "types-setuptools==69.0.0.0\n",
      "typing_extensions==4.5.0\n",
      "tzlocal==5.2\n",
      "uc-micro-py==1.0.2\n",
      "uritemplate==4.1.1\n",
      "urllib3==2.0.7\n",
      "vega-datasets==0.9.0\n",
      "wadllib==1.3.6\n",
      "wasabi==1.1.2\n",
      "wcwidth==0.2.12\n",
      "webcolors==1.13\n",
      "webencodings==0.5.1\n",
      "websocket-client==1.6.4\n",
      "Werkzeug==3.0.1\n",
      "widgetsnbextension==3.6.6\n",
      "wordcloud==1.9.2\n",
      "wrapt==1.14.1\n",
      "xarray==2023.7.0\n",
      "xarray-einstats==0.6.0\n",
      "xgboost==2.0.2\n",
      "xlrd==2.0.1\n",
      "xxhash==3.4.1\n",
      "xyzservices==2023.10.1\n",
      "yarl==1.9.3\n",
      "yellowbrick==1.5\n",
      "yfinance==0.2.32\n",
      "zict==3.0.0\n",
      "zipp==3.17.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "vcAsZvuoiWff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vcAsZvuoiWff",
    "outputId": "e953ee21-be35-4285-ba80-d38c7dd2e191"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting telegram\n",
      "  Downloading telegram-0.0.1.tar.gz (879 bytes)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: telegram\n",
      "  Building wheel for telegram (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for telegram: filename=telegram-0.0.1-py3-none-any.whl size=1293 sha256=309421f82b4c387c8964b32b6d00f0c9ef697a16b29da4c381b63e911c0c7a72\n",
      "  Stored in directory: /root/.cache/pip/wheels/f3/f2/16/dc6d6c6c7e0422206fec62833039a2b4082de3b85e55d32b52\n",
      "Successfully built telegram\n",
      "Installing collected packages: telegram\n",
      "Successfully installed telegram-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install telegram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "-oyIv-l2iWjS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-oyIv-l2iWjS",
    "outputId": "a893557f-682a-4c6b-86bd-08befe38eba2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymorphy2\n",
      "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dawg-python>=0.7.1 (from pymorphy2)\n",
      "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
      "Collecting pymorphy2-dicts-ru<3.0,>=2.4 (from pymorphy2)\n",
      "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting docopt>=0.6 (from pymorphy2)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=48d4b6d7592677e829cf07c0e1982b665f643a510dd01e46843e6e9e1bb1d2c0\n",
      "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
      "Successfully built docopt\n",
      "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
      "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n",
      "Collecting stop_words\n",
      "  Downloading stop-words-2018.7.23.tar.gz (31 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: stop_words\n",
      "  Building wheel for stop_words (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for stop_words: filename=stop_words-2018.7.23-py3-none-any.whl size=32895 sha256=4d2cb09a8d3ae391ce4cab26f339123dd1655f58ef6f01815f7bcbb6ff056664\n",
      "  Stored in directory: /root/.cache/pip/wheels/d0/1a/23/f12552a50cb09bcc1694a5ebb6c2cd5f2a0311de2b8c3d9a89\n",
      "Successfully built stop_words\n",
      "Installing collected packages: stop_words\n",
      "Successfully installed stop_words-2018.7.23\n",
      "Collecting annoy\n",
      "  Downloading annoy-1.17.3.tar.gz (647 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.5/647.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: annoy\n",
      "  Building wheel for annoy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for annoy: filename=annoy-1.17.3-cp310-cp310-linux_x86_64.whl size=552406 sha256=3456081149dbbef29847205121a43c268f9ea6829e4e73387ee1a501a93521e6\n",
      "  Stored in directory: /root/.cache/pip/wheels/64/8a/da/f714bcf46c5efdcfcac0559e63370c21abe961c48e3992465a\n",
      "Successfully built annoy\n",
      "Installing collected packages: annoy\n",
      "Successfully installed annoy-1.17.3\n",
      "Collecting pandarallel\n",
      "  Downloading pandarallel-1.6.5.tar.gz (14 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting dill>=0.3.1 (from pandarallel)\n",
      "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1 in /usr/local/lib/python3.10/dist-packages (from pandarallel) (1.5.3)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from pandarallel) (5.9.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1->pandarallel) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1->pandarallel) (2023.3.post1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1->pandarallel) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1->pandarallel) (1.16.0)\n",
      "Building wheels for collected packages: pandarallel\n",
      "  Building wheel for pandarallel (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pandarallel: filename=pandarallel-1.6.5-py3-none-any.whl size=16672 sha256=9d5b9f65accc9e4fec73f1dc00a22fd665e55cf794e1f3dca02ff849358de7cb\n",
      "  Stored in directory: /root/.cache/pip/wheels/50/4f/1e/34e057bb868842209f1623f195b74fd7eda229308a7352d47f\n",
      "Successfully built pandarallel\n",
      "Installing collected packages: dill, pandarallel\n",
      "Successfully installed dill-0.3.7 pandarallel-1.6.5\n",
      "Collecting python-telegram-bot\n",
      "  Downloading python_telegram_bot-20.7-py3-none-any.whl (552 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m552.6/552.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting httpx~=0.25.2 (from python-telegram-bot)\n",
      "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx~=0.25.2->python-telegram-bot) (3.7.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx~=0.25.2->python-telegram-bot) (2023.11.17)\n",
      "Collecting httpcore==1.* (from httpx~=0.25.2->python-telegram-bot)\n",
      "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx~=0.25.2->python-telegram-bot) (3.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx~=0.25.2->python-telegram-bot) (1.3.0)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx~=0.25.2->python-telegram-bot)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx~=0.25.2->python-telegram-bot) (1.2.0)\n",
      "Installing collected packages: h11, httpcore, httpx, python-telegram-bot\n",
      "Successfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 python-telegram-bot-20.7\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2\n",
    "!pip install stop_words\n",
    "!pip install annoy\n",
    "!pip install pandarallel\n",
    "!pip install python-telegram-bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d420819",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5d420819",
    "outputId": "0f98ba4f-a1c9-47f4-d3ac-74f4b8259979"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 1 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from telegram.ext import Updater, CommandHandler, MessageHandler, filters\n",
    "import string\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from stop_words import get_stop_words\n",
    "import annoy\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13c39f7e",
   "metadata": {
    "id": "13c39f7e"
   },
   "outputs": [],
   "source": [
    "import mmap\n",
    "import re\n",
    "\n",
    "def get_num_lines(file_path):\n",
    "    fp = open(file_path, \"r+\")\n",
    "    buf = mmap.mmap(fp.fileno(), 0)\n",
    "    lines = 0\n",
    "    while buf.readline():\n",
    "        lines += 1\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "h_r7y1MMm81c",
   "metadata": {
    "id": "h_r7y1MMm81c"
   },
   "outputs": [],
   "source": [
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "Nbio850sm85C",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "Nbio850sm85C",
    "outputId": "0c26baf6-8cca-472b-955a-d08b3d89a0ac"
   },
   "outputs": [],
   "source": [
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb65453f",
   "metadata": {
    "id": "fb65453f"
   },
   "outputs": [],
   "source": [
    "# Преобразование файла вопросов-ответов в строчный вид\n",
    "if not os.path.isfile('prepared_answers.txt'):\n",
    "\n",
    "    question = None\n",
    "    written = False\n",
    "\n",
    "    with open(\"prepared_answers.txt\", \"w\") as fout:\n",
    "        with open(\"Otvety.txt\", \"r\") as fin:\n",
    "            for line in tqdm_notebook(fin):\n",
    "                if line.startswith(\"---\"):\n",
    "                    written = False\n",
    "                    continue\n",
    "                if not written and question is not None:\n",
    "                    fout.write(question.replace(\"\\t\", \" \").strip() + \"\\t\" + line.replace(\"\\t\", \" \"))\n",
    "                    written = True\n",
    "                    question = None\n",
    "                    continue\n",
    "                if not written:\n",
    "                    question = line.strip()\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GsxwTUuZQWlJ",
   "metadata": {
    "id": "GsxwTUuZQWlJ"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Otvety.txt\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e118857",
   "metadata": {
    "id": "2e118857"
   },
   "outputs": [],
   "source": [
    "# Препроцессинг текста\n",
    "def preprocess_txt(line):\n",
    "    spls = \"\".join(i for i in line.strip() if i not in exclude).split()\n",
    "    spls = [morpher.parse(i.lower())[0].normal_form for i in spls]\n",
    "    spls = [i for i in spls if i not in sw and i != \"\"]\n",
    "    return spls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2109a53d",
   "metadata": {
    "id": "2109a53d"
   },
   "outputs": [],
   "source": [
    "# Функция для очистки текста из статьи https://habr.com/ru/articles/738176/ адаптированная под русский язык\n",
    "def clean_text(input_text):\n",
    "\n",
    "    # HTML-теги: первый шаг - удалить из входного текста все HTML-теги\n",
    "    clean_text = re.sub('<[^<]+?>', '', input_text)\n",
    "\n",
    "    # URL и ссылки: далее - удаляем из текста все URL и ссылки\n",
    "    clean_text = re.sub(r'http\\S+', '', clean_text)\n",
    "\n",
    "    #Эмоджи и эмотиконы: используем собственную функцию для преобразования эмоджи в текст\n",
    "    #Важно понимать эмоциональную окраску обрабатываемого текста\n",
    "    clean_text = emojis_words(clean_text)\n",
    "\n",
    "    # Приводим все входные данные к нижнему регистру\n",
    "    clean_text = clean_text.lower()\n",
    "\n",
    "    # Убираем все пробелы\n",
    "    # Так как все данные теперь представлены словами - удалим пробелы\n",
    "    clean_text = re.sub('\\s+', ' ', clean_text)\n",
    "\n",
    "    #Убираем специальные символы: избавляемся от всего, что не является \"словами\"\n",
    "    clean_text = re.sub('[^а-яА-ЯёЁ0-9\\s]', '', clean_text) #\n",
    "\n",
    "    # Записываем числа прописью: 100 превращается в \"сто\" (для компьютера)# не работает\n",
    "    temp = inflect.engine()\n",
    "    words = []\n",
    "    for word in clean_text.split():\n",
    "        if word.isdigit():\n",
    "            words.append(num2words(int(word), lang='ru'))\n",
    "        else:\n",
    "            words.append(word)\n",
    "    clean_text = ' '.join(words)\n",
    "\n",
    "        # Стоп-слова: удаление стоп-слов - это стандартная практика очистки текстов\n",
    "    stop_words = set(stopwords.words('russian'))\n",
    "    tokens = word_tokenize(clean_text)\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    clean_text = ' '.join(tokens)\n",
    "\n",
    "    # Знаки препинания: далее - удаляем из текста все знаки препинания\n",
    "    clean_text = re.sub(r'[^\\w\\s]', '', clean_text)\n",
    "\n",
    "    # И наконец - возвращаем очищенный текст\n",
    "    return clean_text\n",
    "\n",
    "# Функция для преобразования эмоджи в слова\n",
    "def emojis_words(text):\n",
    "\n",
    "    # Модуль emoji: преобразование эмоджи в их словесные описания\n",
    "    clean_text = emoji.demojize(text, delimiters=(\" \", \" \"))\n",
    "\n",
    "    # Редактирование текста путём замены \":\" и\" _\", а так же - путём добавления пробела между отдельными словами\n",
    "    clean_text = clean_text.replace(\":\", \"\").replace(\"_\", \" \")\n",
    "\n",
    "    return clean_text\n",
    "\n",
    "def preproc_text(text):\n",
    "    res = str(text).strip()\n",
    "    res = re.sub(r\"\\s+\", \" \", res)\n",
    "    return res\n",
    "\n",
    "def build_data(data_q, data_ans):\n",
    "    data = []\n",
    "    for idx, texts in enumerate(data_q):\n",
    "        question = preproc_text(texts)\n",
    "        answer = preproc_text(data_ans.iloc[idx])\n",
    "        res = '\\nx:' + question + '\\ny:' + answer\n",
    "        data.append(res)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2K0bMuDSN5rd",
   "metadata": {
    "id": "2K0bMuDSN5rd"
   },
   "outputs": [],
   "source": [
    "!pip install pymorphy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f86eb04",
   "metadata": {
    "id": "2f86eb04"
   },
   "outputs": [],
   "source": [
    "# Обработка текста\n",
    "from pymorphy3 import MorphAnalyzer\n",
    "\n",
    "sentences = []\n",
    "morpher = MorphAnalyzer()\n",
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(string.punctuation)\n",
    "c = 0\n",
    "\n",
    "file_path_from = 'prepared_answers.txt'\n",
    "file_path_to = 'Otvety2.txt'\n",
    "\n",
    "if not os.path.isfile(file_path_to):\n",
    "\n",
    "    N = get_num_lines(file_path_from)\n",
    "    with open(file_path_to, mode = 'w') as fileto:\n",
    "        with open(file_path_from) as filefrom:\n",
    "            for k in tqdm(range(N)):\n",
    "                line = filefrom.readline()\n",
    "                if line == '': break\n",
    "                spls = preprocess_txt(line)\n",
    "                sentences.append(spls)\n",
    "                c += 1\n",
    "                if c > 500000000:\n",
    "                    break\n",
    "                fileto.write(' '.join(spls)+'\\n')\n",
    "    filefrom.close()\n",
    "    fileto.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdb954d",
   "metadata": {
    "id": "4bdb954d"
   },
   "outputs": [],
   "source": [
    "# Загрузим результат\n",
    "\n",
    "sentences = []\n",
    "\n",
    "file_path_from = 'Otvety2.txt'\n",
    "if os.path.isfile(file_path_from):\n",
    "    N = get_num_lines(file_path_from)\n",
    "    with open(file_path_to, mode = 'r') as filefrom:\n",
    "        for k in tqdm(range(N)):\n",
    "            line = filefrom.readline()\n",
    "            if line == '': break\n",
    "            sentences.append(line.split())\n",
    "    filefrom.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8tz1J6tTOCAg",
   "metadata": {
    "id": "8tz1J6tTOCAg"
   },
   "outputs": [],
   "source": [
    "vec = []\n",
    "_ = [vec.extend(x)  for x in sentences[:100]]\n",
    "vec = list(set(vec))\n",
    "vec.sort()\n",
    "vec[20:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lEl3mrU3OCDC",
   "metadata": {
    "id": "lEl3mrU3OCDC"
   },
   "outputs": [],
   "source": [
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_H9s3bWpOlSb",
   "metadata": {
    "id": "_H9s3bWpOlSb"
   },
   "source": [
    "Обучим модель FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XJMiojO6OCGE",
   "metadata": {
    "id": "XJMiojO6OCGE"
   },
   "outputs": [],
   "source": [
    "file_path_from = 'ft_model'\n",
    "if not os.path.isfile(file_path_from):\n",
    "\n",
    "    sentences = [i for i in tqdm(sentences) if len(i) > 2]\n",
    "    modelFT = FastText(sentences=sentences, size=100, min_count=1, window=5)\n",
    "    modelFT.save(\"ft_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae19cdef",
   "metadata": {
    "id": "ae19cdef"
   },
   "outputs": [],
   "source": [
    "modelFT = FastText.load(\"ft_model\")\n",
    "ft_index = annoy.AnnoyIndex(100 ,'angular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kDbySBxNOkB_",
   "metadata": {
    "id": "kDbySBxNOkB_"
   },
   "outputs": [],
   "source": [
    "list(set(get_stop_words(\"ru\")))[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czTohA7hO6Mq",
   "metadata": {
    "id": "czTohA7hO6Mq"
   },
   "source": [
    "Индексы для вопросов-ответов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HTAFWkRBOkEX",
   "metadata": {
    "id": "HTAFWkRBOkEX"
   },
   "outputs": [],
   "source": [
    "file_path_from = 'speaker.ann'\n",
    "if not os.path.isfile(file_path_from):\n",
    "    morpher = MorphAnalyzer()\n",
    "    sw = set(get_stop_words(\"ru\"))\n",
    "    exclude = set(string.punctuation)\n",
    "    modelFT = FastText.load(\"ft_model\")\n",
    "    ft_index = annoy.AnnoyIndex(100 ,'angular')\n",
    "\n",
    "    index_map = {}\n",
    "    counter = 0\n",
    "    with open(\"Otvety2.txt\", \"r\") as f:\n",
    "        for line in tqdm(f):\n",
    "            n_ft = 0\n",
    "            spls = line.split(\"\\t\")\n",
    "            index_map[counter] = spls[1]\n",
    "            question = preprocess_txt(spls[0])\n",
    "            vector_ft = np.zeros(100)\n",
    "            for word in question:\n",
    "                if word in modelFT.wv:\n",
    "                    vector_ft += modelFT.wv[word]\n",
    "                    n_ft += 1\n",
    "            if n_ft > 0:\n",
    "                vector_ft = vector_ft / n_ft\n",
    "            ft_index.add_item(counter, vector_ft)\n",
    "\n",
    "            counter += 1\n",
    "\n",
    "            if counter > 50_000:\n",
    "                break\n",
    "\n",
    "    ft_index.build(10)\n",
    "    ft_index.save('speaker.ann')\n",
    "\n",
    "    with open(\"index_speaker.pkl\", \"wb\") as f:\n",
    "        pickle.dump(index_map, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zcTowv6COkHR",
   "metadata": {
    "id": "zcTowv6COkHR"
   },
   "outputs": [],
   "source": [
    "#Загрузим индексы\n",
    "ft_index = annoy.AnnoyIndex(100, 'angular')\n",
    "ft_index.load('speaker.ann')\n",
    "index_map = pd.read_pickle(\"index_speaker.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60Ra8t6PO_Xu",
   "metadata": {
    "id": "60Ra8t6PO_Xu"
   },
   "outputs": [],
   "source": [
    "np.random.permutation(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gIbokfPzO_aH",
   "metadata": {
    "id": "gIbokfPzO_aH"
   },
   "outputs": [],
   "source": [
    "a = ft_index.get_nns_by_vector(np.random.permutation(100), 5, include_distances=True)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ozViqCSRO_cv",
   "metadata": {
    "id": "ozViqCSRO_cv"
   },
   "outputs": [],
   "source": [
    "[index_map[x] for x in a[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7LBWB3o4P8p2",
   "metadata": {
    "id": "7LBWB3o4P8p2"
   },
   "source": [
    "Модель продуктовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcisA3ISPOvg",
   "metadata": {
    "id": "bcisA3ISPOvg"
   },
   "outputs": [],
   "source": [
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OMjsatzGPOyX",
   "metadata": {
    "id": "OMjsatzGPOyX"
   },
   "outputs": [],
   "source": [
    "shop_data = pd.read_csv(\"ProductsDataset.csv\")\n",
    "\n",
    "shop_data['text'] = shop_data['title'] + \" \" + shop_data[\"descrirption\"]\n",
    "shop_data['text'] = shop_data['text'].progress_apply(lambda x: preprocess_txt(str(x)))\n",
    "shop_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JLAGa8KDPO0x",
   "metadata": {
    "id": "JLAGa8KDPO0x"
   },
   "outputs": [],
   "source": [
    "#Векторизация\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6nlPz-NbPO3V",
   "metadata": {
    "id": "6nlPz-NbPO3V"
   },
   "outputs": [],
   "source": [
    "idxs = set(np.random.randint(0, len(index_map), len(shop_data)))\n",
    "# Вопрос-ответный домен\n",
    "negative_texts = [\" \".join(preprocess_txt(index_map[i])) for i in tqdm(idxs)]\n",
    "# Продуктовый домен\n",
    "positive_texts = [\" \".join(val) for val in tqdm(shop_data['text'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dJgzXqc7OkKH",
   "metadata": {
    "id": "dJgzXqc7OkKH"
   },
   "outputs": [],
   "source": [
    "#разбивка на положительный/отрицательный\n",
    "dataset = negative_texts + positive_texts\n",
    "labels = np.zeros(len(dataset))\n",
    "labels[len(negative_texts):] = np.ones(len(positive_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "igO2bLooRWdC",
   "metadata": {
    "id": "igO2bLooRWdC"
   },
   "outputs": [],
   "source": [
    "#сплитуем на трейн  и тест\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, labels, test_size=0.2,\n",
    "                                                    stratify=labels, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XprOFxDcR3Mn",
   "metadata": {
    "id": "XprOFxDcR3Mn"
   },
   "source": [
    "Обучим простую модель Логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HDV49LqIRWga",
   "metadata": {
    "id": "HDV49LqIRWga"
   },
   "outputs": [],
   "source": [
    "x_train_vec = vectorizer.fit_transform(X_train)\n",
    "x_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "lr = LogisticRegression().fit(x_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eif9AgarRWi6",
   "metadata": {
    "id": "eif9AgarRWi6"
   },
   "outputs": [],
   "source": [
    "#проверим метрики точности и Tfidf-веса\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MofKzSJzSB1Q",
   "metadata": {
    "id": "MofKzSJzSB1Q"
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_true=y_test, y_pred=lr.predict(x_test_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RxwcNWEESB3r",
   "metadata": {
    "id": "RxwcNWEESB3r"
   },
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer().fit(X_train)\n",
    "np.mean(tfidf_vect.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1S2V44VeSB6D",
   "metadata": {
    "id": "1S2V44VeSB6D"
   },
   "outputs": [],
   "source": [
    "idfs = {v[0]: v[1] for v in zip(tfidf_vect.vocabulary_, tfidf_vect.idf_)}\n",
    "list(idfs.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "G5yDACBPTE9w",
   "metadata": {
    "id": "G5yDACBPTE9w"
   },
   "outputs": [],
   "source": [
    "list(idfs.values())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PIHZjv1ATwrh",
   "metadata": {
    "id": "PIHZjv1ATwrh"
   },
   "source": [
    "Индексы для данных по товарам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "C_FGpoz7TFCu",
   "metadata": {
    "id": "C_FGpoz7TFCu"
   },
   "outputs": [],
   "source": [
    "file_path_from = 'shop.ann'\n",
    "if not os.path.isfile(file_path_from):\n",
    "\n",
    "\n",
    "    ft_index_shop = annoy.AnnoyIndex(100 ,'angular')\n",
    "\n",
    "    midf = np.mean(tfidf_vect.idf_)\n",
    "\n",
    "    index_map_shop = {}\n",
    "    counter = 0\n",
    "\n",
    "    for i in tqdm(range(len(shop_data))):\n",
    "        n_ft = 0\n",
    "        index_map_shop[counter] = (shop_data.loc[i, \"title\"], shop_data.loc[i, \"image_links\"])\n",
    "        vector_ft = np.zeros(100)\n",
    "        for word in shop_data.loc[i, \"text\"]:\n",
    "            if word in modelFT.wv:\n",
    "                vector_ft += modelFT.wv[word] * idfs.get(word, midf)\n",
    "                n_ft += idfs.get(word, midf)\n",
    "        if n_ft > 0:\n",
    "            vector_ft = vector_ft / n_ft\n",
    "        ft_index_shop.add_item(counter, vector_ft)\n",
    "        counter += 1\n",
    "\n",
    "    ft_index_shop.build(10)\n",
    "    ft_index_shop.save('shop.ann')\n",
    "\n",
    "    file_path_from = 'index_shop.pkl'\n",
    "    if not os.path.isfile(file_path_from):\n",
    "\n",
    "        with open(\"index_shop.pkl\", \"wb\") as f:\n",
    "            pickle.dump(index_map_shop, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CeZqOX6BTseR",
   "metadata": {
    "id": "CeZqOX6BTseR"
   },
   "outputs": [],
   "source": [
    "#Загрузим индексы\n",
    "midf = np.mean(tfidf_vect.idf_)\n",
    "\n",
    "ft_index_shop = annoy.AnnoyIndex(100, 'angular')\n",
    "ft_index_shop.load('shop.ann')\n",
    "\n",
    "index_map_shop = pd.read_pickle(\"index_shop.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bH23VS_LTsgq",
   "metadata": {
    "id": "bH23VS_LTsgq"
   },
   "outputs": [],
   "source": [
    "#Функция векторизации текста\n",
    "def embed_txt(txt, idfs, midf):\n",
    "    n_ft = 0\n",
    "    vector_ft = np.zeros(100)\n",
    "    for word in txt:\n",
    "        if word in modelFT.wv:\n",
    "            vector_ft += modelFT.wv[word] * idfs.get(word, midf)\n",
    "            n_ft += idfs.get(word, midf)\n",
    "    return vector_ft / n_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JbCPyp_DSB9s",
   "metadata": {
    "id": "JbCPyp_DSB9s"
   },
   "outputs": [],
   "source": [
    "ft_index_shop.get_nns_by_vector(np.ones(100)*20, 5, include_distances=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aEPJZUdKUSd2",
   "metadata": {
    "id": "aEPJZUdKUSd2"
   },
   "source": [
    "Создание бота в телеграмм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cD9DXmKKUJsY",
   "metadata": {
    "id": "cD9DXmKKUJsY"
   },
   "outputs": [],
   "source": [
    "\n",
    "updater = Updater(\"6838788278:AAEe3f2qu7f9tJNGvkDY2-iXbD46lln539I\", use_context=True) # Токен API к Telegram\n",
    "dispatcher = updater.dispatcher\n",
    "\n",
    "def startCommand(update, context):\n",
    "    context.bot.send_message(chat_id=update.message.chat_id, text='Привет.')\n",
    "\n",
    "def textMessage(update, context):\n",
    "\n",
    "    input_txt = preprocess_txt(update.message.text)\n",
    "    vect = vectorizer.transform([\" \".join(input_txt)])\n",
    "    prediction = lr.predict(vect)\n",
    "\n",
    "\n",
    "    if prediction[0] == 1:\n",
    "        vect_ft = embed_txt(input_txt, idfs, midf)\n",
    "        ft_index_shop_val = ft_index_shop.get_nns_by_vector(vect_ft, 5)\n",
    "        for item in ft_index_shop_val:\n",
    "            title, image = index_map_shop[item]\n",
    "            context.bot.send_message(chat_id=update.message.chat_id, text=\"title: {} image: {}\".format(title, image))\n",
    "        return\n",
    "\n",
    "    #Товары\n",
    "    vect_ft = embed_txt(input_txt, {}, 1)\n",
    "    ft_index_val, distances = ft_index.get_nns_by_vector(vect_ft, 1, include_distances=True)\n",
    "\n",
    "\n",
    "    if distances[0] > 100.5:\n",
    "        print(distances[0])\n",
    "        context.bot.send_message(chat_id=update.message.chat_id, text=\"Моя твоя не понимать\")\n",
    "        return\n",
    "\n",
    "    # Вопрос-Ответ\n",
    "    context.bot.send_message(chat_id=update.message.chat_id, text=index_map[ft_index_val[0]])\n",
    "\n",
    "start_command_handler = CommandHandler('start', startCommand)\n",
    "text_message_handler = MessageHandler(Filters.text, textMessage)\n",
    "dispatcher.add_handler(start_command_handler)\n",
    "dispatcher.add_handler(text_message_handler)\n",
    "updater.start_polling(clean=True)\n",
    "updater.idle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kIbuPe04UJuu",
   "metadata": {
    "id": "kIbuPe04UJuu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mIh0YaQ8UJxT",
   "metadata": {
    "id": "mIh0YaQ8UJxT"
   },
   "outputs": [],
   "source": [
    "#Настройки\n",
    "from telegram.ext  import Updater, CommandHandler, MessageHandler, filters, CallbackContext\n",
    "import dialogflow\n",
    "import logging\n",
    "\n",
    "updater = Updater(token='6838788278:AAEe3f2qu7f9tJNGvkDY2-iXbD46lln539I') # Токен API к Telegram\n",
    "dispatcher = updater.dispatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xImKIV7vRWmS",
   "metadata": {
    "id": "xImKIV7vRWmS"
   },
   "outputs": [],
   "source": [
    "def startCommand(bot, update):\n",
    "    bot.send_message(chat_id=update.message.chat_id, text='Привет')\n",
    "\n",
    "def textMessage(bot, update):\n",
    "    response = 'Ваше сообщение принял ' + update.message.text # формируем текст ответа\n",
    "    bot.send_message(chat_id=update.message.chat_id, text=response)\n",
    "\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO\n",
    ")\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "def start(update: Update, context: CallbackContext):\n",
    "    update.message.reply_text('Привет!')\n",
    "\n",
    "def echo(update: Update, context: CallbackContext):\n",
    "    txt = update.message.text\n",
    "\n",
    "    update.message.reply_text('Ваше сообщение! ' + update.message.text)\n",
    "\n",
    "updater = Updater(\"6838788278:AAEe3f2qu7f9tJNGvkDY2-iXbD46lln539I\", use_context=True)\n",
    "dispatcher = updater.dispatcher\n",
    "\n",
    "# команды для ответа в Telegram\n",
    "dispatcher.add_handler(CommandHandler(\"start\", start))\n",
    "dispatcher.add_handler(MessageHandler(Filters.text & ~Filters.command, echo))\n",
    "\n",
    "# запуск бота\n",
    "updater.start_polling()\n",
    "updater.idle()\n",
    "\n",
    "'''Создаём папку Bot, в которой потом создаём файл bot.py.\n",
    "Вы можете создать просто текстовый блокнот и вместо расширения .txt напишите .py\n",
    "Собираем код нашего бота. Открываем консоль и переходим в директорию с файлом,\n",
    " и запускаем python3 bot.py Бот будет работать пока будет открыто окно консоли.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s_zKkA6VYONk",
   "metadata": {
    "id": "s_zKkA6VYONk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PJtSAc6qWXKY",
   "metadata": {
    "id": "PJtSAc6qWXKY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
